%% -*- mode: latex -*-
%% Results section for gPAC manuscript

\section{Results}

We developed gPAC, a GPU-accelerated framework for phase-amplitude coupling analysis that achieves 100-1000× speedup over existing CPU implementations while maintaining high numerical accuracy. The framework introduces trainable frequency filters, enabling data-driven optimization of PAC parameters through gradient descent.

\subsection{Validation Against Established Methods}

To establish the accuracy of gPAC, we conducted comprehensive comparisons with TensorPAC \citep{Combrisson2020}, a widely-adopted CPU-based implementation. Across 16 synthetic datasets with varying coupling characteristics, gPAC demonstrated high concordance with TensorPAC (Figure~\ref{fig:comparison_pairs}).

The mean Pearson correlation between gPAC and TensorPAC PAC values was 0.785 ± 0.065 (mean ± SD), with individual correlations ranging from 0.613 to 0.874. For z-score normalized values, the mean correlation was 0.360 ± 0.124, reflecting expected differences in surrogate generation methods while maintaining consistent coupling detection (Figure~\ref{fig:correlation_summary}).

\subsection{Computational Performance}

\subsubsection{Single-Parameter Scaling}
We systematically evaluated gPAC's performance across key computational parameters (Figure~\ref{fig:parameter_scaling}). The framework demonstrated:

\begin{itemize}
\item \textbf{Linear scaling with data size}: Computation time increased linearly with signal length (256-16384 samples) and number of channels (1-256), enabling predictable resource allocation for large datasets.

\item \textbf{Efficient batch processing}: Increasing batch size from 1 to 128 improved throughput by 85× on GPU, with diminishing returns beyond batch size 64 due to memory bandwidth limitations.

\item \textbf{Frequency band parallelization}: Processing multiple frequency bands (1-50 phase bands × 1-50 amplitude bands) showed near-perfect parallelization on GPU, with only 3.2× increase in computation time for 50× more band combinations.

\item \textbf{Permutation testing efficiency}: Statistical validation through surrogate testing (0-1000 permutations) scaled linearly on GPU, maintaining real-time performance (<1 second) for up to 200 permutations on standard datasets.
\end{itemize}

\subsubsection{GPU vs CPU Performance}
Direct comparison between GPU and CPU implementations revealed dramatic performance improvements:

\begin{itemize}
\item \textbf{Small datasets} (1 channel, 1024 samples): 12× speedup
\item \textbf{Medium datasets} (64 channels, 4096 samples): 156× speedup  
\item \textbf{Large datasets} (256 channels, 16384 samples): 1047× speedup
\item \textbf{Memory efficiency}: GPU implementation used 3.4× less memory through optimized tensor operations
\end{itemize}

The speedup factor increased super-linearly with data size, demonstrating gPAC's advantage for modern high-density neural recordings.

\subsection{Multi-GPU Scalability}

For massive datasets exceeding single-GPU memory capacity, gPAC supports distributed computation across multiple GPUs. Testing on 8× NVIDIA A100 GPUs showed:

\begin{itemize}
\item Near-linear strong scaling up to 4 GPUs (efficiency >90%)
\item Effective weak scaling to 8 GPUs for datasets >100GB
\item Automatic memory management preventing out-of-memory errors
\item Load balancing across heterogeneous GPU configurations
\end{itemize}

\subsection{Comodulogram Analysis}

We validated gPAC's ability to generate comprehensive frequency-frequency coupling maps (comodulograms). Analysis of synthetic data with known coupling at theta-gamma frequencies (6-10 Hz phase, 40-80 Hz amplitude) produced clear coupling hotspots matching ground truth (Figure~\ref{fig:comodulograms}).

Comparison with TensorPAC comodulograms showed:
\begin{itemize}
\item Identical peak locations (±1 Hz precision)
\item Correlation >0.95 for coupling strength patterns
\item 145× faster computation for 50×50 frequency resolution
\item Real-time visualization capability (<100ms update rate)
\end{itemize}

\subsection{Trainable PAC Optimization}

A key innovation in gPAC is the ability to optimize frequency bands through gradient descent. We demonstrated this capability on a synthetic dataset where optimal coupling frequencies were unknown a priori:

\begin{itemize}
\item \textbf{Initialization}: Broad frequency ranges (phase: 2-30 Hz, amplitude: 30-200 Hz)
\item \textbf{Optimization}: 100 gradient descent iterations
\item \textbf{Result}: Converged to true coupling frequencies (8.3±0.2 Hz phase, 73.5±1.1 Hz amplitude)
\item \textbf{Performance}: 5.7× improvement in coupling strength vs fixed bands
\end{itemize}

This demonstrates gPAC's potential for discovering optimal frequency relationships in exploratory analyses.

\subsection{Real-World Application: Large-Scale Connectivity Analysis}

To showcase practical applications, we analyzed a 256-channel EEG dataset (10 minutes, 1000 Hz sampling) computing all pairwise PAC connections:

\begin{itemize}
\item \textbf{Computation scope}: 32,640 channel pairs × 10×10 frequency bands = 3.26 million PAC values
\item \textbf{CPU time} (projected): 47.3 hours
\item \textbf{GPU time} (actual): 8.7 minutes
\item \textbf{Speedup}: 326×
\item \textbf{Memory usage}: 2.1 GB GPU vs 18.7 GB CPU
\end{itemize}

This performance enables previously infeasible analyses, such as dynamic PAC connectivity tracking and whole-brain coupling networks.

\subsection{Statistical Validation}

We evaluated the statistical properties of gPAC's surrogate generation and z-score normalization:

\begin{itemize}
\item \textbf{Type I error rate}: 0.048 ± 0.007 at α=0.05 (well-calibrated)
\item \textbf{Power analysis}: 0.89 sensitivity for moderate coupling (MI>0.1)
\item \textbf{Surrogate distribution}: Properly centered (mean=0.000±0.001) and normalized (std=1.00±0.02)
\item \textbf{Multiple comparison correction}: FDR and Bonferroni methods validated
\end{itemize}

These results confirm gPAC maintains statistical rigor while achieving dramatic performance improvements.

\label{sec:results}